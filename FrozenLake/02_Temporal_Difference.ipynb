{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed569bb8",
   "metadata": {},
   "source": [
    "# FrozenLake-v1 환경을 통한 Temporal Difference Prediction 실습\n",
    "\n",
    "Monte Carlo prediction은 한 episode가 끝난 후에 얻은 return 값으로 각 state에서 얻은 reward를 시간에 따라 discount factor를 적용해 value function을 update한다. 그러나 이 방법에 쓰이는 episode는 반드시 terminal state를 통해 '끝이 있는' episode를 사용해야 한다. 무한히 긴 episode가 진행되면 Monte Carlo Prediction을 적용하는 것이 어려울 수 있다.\n",
    "\n",
    "Dynamic Programming 에서는 time step마다 full-width update를 통해 학습을 진행했지만 environment에 대한 model 정보가 필요했다.\n",
    "\n",
    "Time-step 마다 학습하면서 model free한 방법인 TD에 대한 기본적인 아이디어를 익히고 실습코드를 작성해보자.\n",
    "\n",
    "> TODO: \n",
    "> TD에 대한 설명 추가 + 수식 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3350ca08",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "068672e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f903f1ec",
   "metadata": {},
   "source": [
    "TD prediction for value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d61b3308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TD_prediction(env, alpha = 0.01, gamma = 1):\n",
    "    V = np.zeros(env.nS)\n",
    "    \n",
    "    for i in range(20000):\n",
    "        state = env.reset()\n",
    "        epochs, reward = 0, 0\n",
    "        done = False\n",
    "        action = env.action_space.sample()\n",
    "        \n",
    "        while not done:\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            next_action = env.action_space.sample()\n",
    "            \n",
    "            if done:\n",
    "                V[state] = (1 - alpha) * V[state] + alpha * reward\n",
    "            else:\n",
    "                V[state] = (1 - alpha) * V[state] + alpha * (reward + gamma * V[next_state])\n",
    "                \n",
    "            state = next_state\n",
    "            action = next_action\n",
    "            epochs += 1\n",
    "            \n",
    "        if i % 100 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print('Episode: {}'.format(i))\n",
    "            \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "131489d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 19900\n",
      "[0.01380267 0.00994827 0.01716553 0.00927513 0.01884445 0.\n",
      " 0.03528116 0.         0.03779247 0.08926983 0.1184477  0.\n",
      " 0.         0.16465493 0.44839986 0.        ]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v1', is_slippery=True)\n",
    "env.render()\n",
    "\n",
    "V = TD_prediction(env)\n",
    "\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5bbe86",
   "metadata": {},
   "source": [
    "TD prediction for Q-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d6721d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TD_Q_prediction(env, alpha = 0.01, gamma = 1):\n",
    "    Q = np.zeros([env.nS, env.nA])\n",
    "    \n",
    "    for i in range(300000):\n",
    "        state = env.reset()\n",
    "        epochs, reward = 0, 0\n",
    "        done = False\n",
    "        action = env.action_space.sample()\n",
    "        \n",
    "        while not done:\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            next_action = env.action_space.sample()\n",
    "            \n",
    "            if done:\n",
    "                Q[state, action] = (1 - alpha) * Q[state, action] + alpha * reward\n",
    "            else:\n",
    "                Q[state, action] = (1 - alpha) * Q[state, action] + alpha * (reward + gamma * Q[next_state, next_action])\n",
    "                \n",
    "            state = next_state\n",
    "            action = next_action\n",
    "            epochs += 1\n",
    "            \n",
    "        if i % 100 == 0:\n",
    "            clear_output(wait = True)\n",
    "            print('Episode: {}'.format(i))\n",
    "            \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b5134a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 299900\n",
      "[[0.01497078 0.01406827 0.01479327 0.01393006]\n",
      " [0.00815489 0.01213798 0.01133971 0.01533416]\n",
      " [0.02339026 0.02216452 0.02309844 0.01403719]\n",
      " [0.01003015 0.01042715 0.00713207 0.01441648]\n",
      " [0.02332183 0.01793433 0.01662275 0.01093528]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.05278772 0.05683548 0.05410334 0.00779289]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.02013643 0.04879552 0.03472303 0.04483682]\n",
      " [0.07508223 0.11968451 0.10597446 0.05952977]\n",
      " [0.17184574 0.16970391 0.14894196 0.04384832]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.09582441 0.20528748 0.24034556 0.18396717]\n",
      " [0.26332687 0.53958625 0.51874199 0.47300494]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v1', is_slippery=True)\n",
    "env.render()\n",
    "\n",
    "Q = TD_Q_prediction(env)\n",
    "\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdd2efc",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- TD($\\lambda$) Prediction"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
